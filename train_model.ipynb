{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Checking for GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Runing on: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our U-Net based model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from unet_model import *\n",
    "from image_utils import *\n",
    "from oral_mice_tissues_dataset import *\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# load the input image (X) and its corresponding mask (Y)\n",
    "dysplasia_level = \"1-healthy\"\n",
    "color_normalization = \"1-original\"\n",
    "X = load_pil_image(\"/home/dalifreire/Documents/Doutorado/github/histological_oral_mice_tissues/roi/image/train/{}/{}/image003-2-roi1.tif\".format(color_normalization, dysplasia_level))\n",
    "y = load_pil_image(\"/home/dalifreire/Documents/Doutorado/github/histological_oral_mice_tissues/roi/mask/{}/image003-2-roi1.tif\".format(dysplasia_level))\n",
    "\n",
    "X, y = data_augmentation(input_image=X, output_mask=y, aug=False)\n",
    "X = X.unsqueeze(0).to(device)\n",
    "y = y.unsqueeze(0).to(device)\n",
    "print('X     --> {}'.format(X.size()))\n",
    "print('y     --> {}'.format(y.size()))\n",
    "\n",
    "\n",
    "# load our u-net based model\n",
    "with torch.no_grad():\n",
    "    model = UNet(in_channels=3, out_channels=1, padding=True).to(device)\n",
    "\n",
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "optimizer.zero_grad()       \n",
    "\n",
    "# runs our u-net based model for the input image (X) and predicts the y_hat output mask\n",
    "y_hat = model(X).squeeze(0)\n",
    "y_hat = TF.to_tensor(np_to_pil(hysteresis_threshold(np_img=y_hat.detach().cpu().numpy()))) # hysteresis threshold\n",
    "print('y_hat --> {}'.format(y_hat.size()))\n",
    "\n",
    "# test the weight update step\n",
    "loss = criterion(y_hat, y)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "\n",
    "# Show the output images\n",
    "X_numpy = X.cpu().numpy()\n",
    "y_numpy = y.cpu().numpy()\n",
    "y_hat_numpy = y_hat.detach().cpu().numpy()\n",
    "\n",
    "f, ax = plt.subplots(1, 3, figsize=(15, 15))\n",
    "ax[0].imshow(X[0].cpu().permute(1, 2, 0))\n",
    "ax[0].set_title('Input image')\n",
    "\n",
    "ax[1].imshow(y_numpy[0], cmap='gray')\n",
    "ax[1].set_title('Target mask')\n",
    "\n",
    "ax[2].imshow(y_hat_numpy[0], cmap='gray')\n",
    "ax[2].set_title('Output mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our U-Net based model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet_model import *\n",
    "from oral_mice_tissues_dataset import *\n",
    "\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# create the datasets\n",
    "batch_size = 1\n",
    "color_normalization = \"1-original\"\n",
    "dataset_dir = \"/home/dalifreire/Documents/Doutorado/github/histological_oral_mice_tissues/roi\"\n",
    "dataloaders = create_dataloader(method=color_normalization, batch_size=batch_size, dataset_dir=dataset_dir)\n",
    "\n",
    "\n",
    "# Checking for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Runing on: {}'.format(device))\n",
    "\n",
    "\n",
    "# load our u-net based model\n",
    "torch.cuda.empty_cache()\n",
    "model = UNet(in_channels=3, out_channels=1, padding=True).to(device)\n",
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "# train the model\n",
    "since = time.time()\n",
    "n_epochs = 500\n",
    "model.train()\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    if (epoch == 1 or epoch == n_epochs or epoch%50 == 0 ):\n",
    "        print(\"\")\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Epoch {}/{} ({:.0f}m {:.0f}s)'.format(epoch, n_epochs, time_elapsed // 60, time_elapsed % 60))\n",
    "        print('-' * 20)\n",
    "    for batch_idx, (data, target, fname, original_size) in enumerate(dataloaders['train']):\n",
    "        \n",
    "        data = Variable(data.to(device))\n",
    "        target = Variable(target.to(device))\n",
    "        #print('X     --> {}'.format(data.size()))\n",
    "        #print('y     --> {}'.format(target.size()))\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        #output = model(data)\n",
    "        output = model(data).squeeze(0)\n",
    "        output = TF.to_tensor(np_to_pil(hysteresis_threshold(np_img=y_hat.detach().cpu().numpy()))) # hysteresis threshold\n",
    "        #print('y_hat --> {}'.format(output.size()))\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch == 1 or epoch == n_epochs or epoch%50 == 0 ) and ((batch_idx+1)%20 == 0):\n",
    "            print('\\tBatch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                (batch_idx+1), \n",
    "                (batch_idx+1) * len(data), \n",
    "                dataset_sizes['train'],\n",
    "                100. *(((batch_idx+1) * len(data)) / dataset_sizes['train']), \n",
    "                loss.item()))\n",
    "        if loss.item() < 0.001 or math.isnan(loss.item()):\n",
    "            break\n",
    "            \n",
    "    #print(\"\\tLoss: {:.6f}\".format(loss.item()))\n",
    "    if loss.item() < 0.001 or math.isnan(loss.item()):\n",
    "        break\n",
    "        \n",
    "time_elapsed = time.time() - since\n",
    "print('-' * 20)\n",
    "print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'batch_size': batch_size,\n",
    "            'dataset': 'OralMiceTissuesDataset_{}'.format(color_normalization),\n",
    "            'model_in_channels': model.model_input_channels(),\n",
    "            'model_out_channels': model.model_output_channels(),\n",
    "            'model_up_mode': model.model_up_mode(),\n",
    "            'model_padding': model.model_padding(),\n",
    "            'criterion': 'nn.BCELoss',\n",
    "            'optimizer': 'optim.Adam',\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "            }, \"{}__Dataset-{}__Epoch-{}__Size-448x256.pt\".format(model.name(), color_normalization, epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runs our trained U-Net based model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet_model import *\n",
    "from oral_mice_tissues_dataset import *\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import utils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#model = load_checkpoint(file_path=\"{}__Dataset-{}__Epoch-{}__Size-448x256.pt\".format(model.name(), color_normalization, epoch))\n",
    "\n",
    "\n",
    "# create the datasets\n",
    "batch_size = 1\n",
    "color_normalization = \"1-original\"\n",
    "dataset_dir = \"/home/dalifreire/Documents/Doutorado/github/histological_oral_mice_tissues/roi\"\n",
    "dataloaders = create_dataloader(method=color_normalization, batch_size=batch_size, dataset_dir=dataset_dir)\n",
    "\n",
    "\n",
    "# Checking for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Runing on: {}'.format(device))\n",
    "\n",
    "\n",
    "# directory to save results\n",
    "results_dir = \"results/{}\".format(color_normalization)\n",
    "if not os.path.exists(Path(results_dir)):\n",
    "    os.makedirs(Path(results_dir))\n",
    "\n",
    "\n",
    "# iterate over test dataset images        \n",
    "for batch_idx, (images, masks, fname, original_size) in enumerate(dataloaders['test']):\n",
    "    \n",
    "    \n",
    "    X = Variable(images.to(device))\n",
    "    print('Batch {}: {}/{} images: {} masks: {}'.format(\n",
    "        (batch_idx+1), \n",
    "        (batch_idx+1) * len(images), \n",
    "        len(dataloaders['test'].dataset),\n",
    "        images.shape,\n",
    "        masks.shape))\n",
    "    \n",
    "    \n",
    "    y_hat = model(X).squeeze(0)\n",
    "    X_numpy = X.cpu().numpy()\n",
    "    y_hat_numpy = y_hat.detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    input_image_filename = '{}/{} - input.png'.format(results_dir, fname[0][0:-4])\n",
    "    mask_image_filename = '{}/{} - mask.png'.format(results_dir, fname[0][0:-4])\n",
    "    output_image_filename = '{}/{} - output.png'.format(results_dir, fname[0][0:-4])\n",
    "    f, ax = plt.subplots(1, 3, figsize=(20, 20))\n",
    "    \n",
    "    \n",
    "    # save the input image\n",
    "    input_image = images[0]\n",
    "    utils.save_image(input_image, input_image_filename)\n",
    "    ax[0].imshow(input_image.permute(1, 2, 0))\n",
    "    ax[0].set_title('{} (input)'.format(fname[0]))\n",
    "    \n",
    "    # save the mask image\n",
    "    mask_image = masks[0]\n",
    "    utils.save_image(output_image, output_image_filename)\n",
    "    ax[1].imshow(mask_image, cmap='gray')\n",
    "    ax[1].set_title('{} (output)'.format(fname[0]))\n",
    "    \n",
    "    # save the predicted output image\n",
    "    output_image = y_hat[0]\n",
    "    utils.save_image(output_image, output_image_filename)\n",
    "    ax[2].imshow(output_image.squeeze(0).detach().cpu().numpy(), cmap='gray')\n",
    "    ax[2].set_title('{} (output)'.format(fname[0]))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
