{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Checking for GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Runing on: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our U-Net based model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from unet_model import *\n",
    "from image_utils import *\n",
    "from oral_mice_tissues_dataset import *\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# load the input image (X) in LAB color model and its corresponding mask (Y)\n",
    "dysplasia_level = \"1-healthy\"\n",
    "color_normalization = \"1-original\"\n",
    "X = load_pil_image(\"../histological_oral_mice_tissues/roi/image/train/{}/{}/image003-2-roi1.tif\".format(color_normalization, dysplasia_level), False, \"LAB\")\n",
    "y = load_pil_image(\"../histological_oral_mice_tissues/roi/mask/{}/image003-2-roi1.tif\".format(dysplasia_level))\n",
    "\n",
    "X, y = data_augmentation(input_image=X, output_mask=y, aug=False)\n",
    "X = X[0] # 'l' channel from lab\n",
    "X = Variable(X.unsqueeze(0).unsqueeze(0).to(device)) #X = Variable(X.unsqueeze(0).to(device))\n",
    "y = Variable(y.unsqueeze(0).to(device))\n",
    "print('X     --> {}'.format(X.size()))\n",
    "print('y     --> {}'.format(y.size()))\n",
    "\n",
    "\n",
    "# load our u-net based model\n",
    "with torch.no_grad():\n",
    "    model = UNet(in_channels=1, out_channels=1, padding=True).to(device)\n",
    "\n",
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "optimizer.zero_grad()       \n",
    "\n",
    "# runs our u-net based model for the input image (X) and predicts the y_hat output mask\n",
    "y_hat = model(X).squeeze(0)\n",
    "print('y_hat --> {}'.format(y_hat.size()))\n",
    "\n",
    "# test the weight update step\n",
    "loss = criterion(y_hat, y)\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "\n",
    "# Show the output images\n",
    "X_numpy = X.cpu().numpy()\n",
    "y_numpy = y.cpu().numpy()\n",
    "y_hat_numpy = y_hat.detach().cpu().numpy()\n",
    "\n",
    "f, ax = plt.subplots(1, 3, figsize=(15, 15))\n",
    "ax[0].imshow(X[0][0].cpu())\n",
    "ax[0].set_title('Input image')\n",
    "\n",
    "ax[1].imshow(y_numpy[0], cmap='gray')\n",
    "ax[1].set_title('Target mask')\n",
    "\n",
    "ax[2].imshow(y_hat_numpy[0], cmap='gray')\n",
    "ax[2].set_title('Output mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our U-Net based model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet_model import *\n",
    "from oral_mice_tissues_dataset import *\n",
    "\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# create the datasets\n",
    "batch_size = 1\n",
    "color_normalization = \"1-original\"\n",
    "dataset_dir = \"../histological_oral_mice_tissues/roi\"\n",
    "color_model = \"LAB\"\n",
    "dataloaders = create_dataloader(color_normalization, batch_size, dataset_dir, color_model)\n",
    "\n",
    "\n",
    "# Checking for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Runing on: {}'.format(device))\n",
    "\n",
    "\n",
    "# load our u-net based model\n",
    "torch.cuda.empty_cache()\n",
    "model = UNet(in_channels=1, out_channels=1, padding=True).to(device)\n",
    "#model = load_checkpoint(file_path=\"UNet_IN-3_OUT-1_UPMODE-ConvTranspose__Dataset-1-original__Epoch-263__Size-448x256_LAB.pt\")\n",
    "criterion = nn.BCELoss().to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "\n",
    "# train the model\n",
    "since = time.time()\n",
    "n_epochs = 500\n",
    "start_epoch = 1\n",
    "model.train()\n",
    "for epoch in range(start_epoch, n_epochs+1):\n",
    "\n",
    "    if (epoch == start_epoch or epoch == n_epochs or epoch%50 == 0 ):\n",
    "        print(\"\")\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Epoch {}/{} ({:.0f}m {:.0f}s)'.format(epoch, n_epochs, time_elapsed // 60, time_elapsed % 60))\n",
    "        print('-' * 20)\n",
    "    for batch_idx, (data, target, fname, original_size) in enumerate(dataloaders['train']):\n",
    "        \n",
    "        # N x C x H x W\n",
    "        data = Variable(data.to(device))[:, 0, :, :].unsqueeze(1) # 'l' channel from lab\n",
    "        target = Variable(target.to(device))\n",
    "        #print('X     --> {}'.format(data.size()))\n",
    "        #print('y     --> {}'.format(target.size()))\n",
    "                \n",
    "        optimizer.zero_grad()\n",
    "        #output = model(data)\n",
    "        output = model(data).squeeze(0)\n",
    "        #print('y_hat --> {}'.format(output.size()))\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch == start_epoch or epoch == n_epochs or epoch%50 == 0 ) and ((batch_idx+1)%20 == 0):\n",
    "            print('\\tBatch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                (batch_idx+1), \n",
    "                (batch_idx+1) * len(data), \n",
    "                len(dataloaders['train'].dataset),\n",
    "                100. *(((batch_idx+1) * len(data)) / len(dataloaders['train'].dataset)), \n",
    "                loss.item()))\n",
    "        if loss.item() < 0.001 or math.isnan(loss.item()):\n",
    "            break\n",
    "            \n",
    "    #print(\"\\tLoss: {:.6f}\".format(loss.item()))\n",
    "    if loss.item() < 0.001 or math.isnan(loss.item()):\n",
    "        break\n",
    "        \n",
    "time_elapsed = time.time() - since\n",
    "print('-' * 20)\n",
    "print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "\n",
    "# Save the trained model\n",
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'batch_size': batch_size,\n",
    "            'dataset': 'OralMiceTissuesDataset_{}'.format(color_normalization),\n",
    "            'model_in_channels': model.model_input_channels(),\n",
    "            'model_out_channels': model.model_output_channels(),\n",
    "            'model_up_mode': model.model_up_mode(),\n",
    "            'model_padding': model.model_padding(),\n",
    "            'criterion': 'nn.BCELoss',\n",
    "            'optimizer': 'optim.Adam',\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "            }, \"{}__Dataset-{}__Epoch-{}__Size-448x256_LAB_l.pt\".format(model.name(), color_normalization, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "            'epoch': epoch,\n",
    "            'batch_size': batch_size,\n",
    "            'dataset': 'OralMiceTissuesDataset_{}'.format(color_normalization),\n",
    "            'model_in_channels': model.model_input_channels(),\n",
    "            'model_out_channels': model.model_output_channels(),\n",
    "            'model_up_mode': model.model_up_mode(),\n",
    "            'model_padding': model.model_padding(),\n",
    "            'criterion': 'nn.BCELoss',\n",
    "            'optimizer': 'optim.Adam',\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss\n",
    "            }, \"{}__Dataset-{}__Epoch-{}__Size-448x256_LAB_l.pt\".format(model.name(), color_normalization, epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runs our trained U-Net based model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet_model import *\n",
    "from oral_mice_tissues_dataset import *\n",
    "\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import utils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# create the datasets\n",
    "batch_size = 1\n",
    "color_normalization = \"1-original\"\n",
    "dataset_dir = \"../histological_oral_mice_tissues/roi\"\n",
    "color_model = \"LAB\"\n",
    "dataloaders = create_dataloader(color_normalization, batch_size, dataset_dir, color_model)\n",
    "\n",
    "\n",
    "# Checking for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print()\n",
    "print('Runing on: {}'.format(device))\n",
    "\n",
    "\n",
    "# iterate over test dataset images            \n",
    "t1 = datetime.now()  \n",
    "for batch_idx, (images, masks, fname, original_size) in enumerate(dataloaders['test']):\n",
    "    \n",
    "    \n",
    "    X = Variable(images.to(device))[:, 0, :, :].unsqueeze(1) # 'l' channel from lab\n",
    "    print('Batch {}: {}/{} images: {} masks: {} {}'.format(\n",
    "        (batch_idx+1), \n",
    "        (batch_idx+1) * len(images), \n",
    "        len(dataloaders['test'].dataset),\n",
    "        images.shape,\n",
    "        masks.shape,\n",
    "        datetime.now()))\n",
    "    \n",
    "    \n",
    "    y_hat = model(X).squeeze(0)\n",
    "    X_numpy = X.cpu().numpy()\n",
    "    y_hat_numpy = y_hat.detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    f, ax = plt.subplots(1, 3, figsize=(20, 20))\n",
    "    \n",
    "    \n",
    "    # show the input image\n",
    "    input_image = images[0][0] # 'l' channel from lab\n",
    "    ax[0].imshow(input_image)\n",
    "    ax[0].set_title('{} (input)'.format(fname[0]))\n",
    "    \n",
    "    # show the mask image\n",
    "    mask_image = masks[0]\n",
    "    ax[1].imshow(mask_image, cmap='gray')\n",
    "    ax[1].set_title('{} (mask)'.format(fname[0]))\n",
    "    \n",
    "    # show the predicted output image\n",
    "    output_image = y_hat[0].squeeze(0).detach().cpu().numpy()\n",
    "    output_image_otsu  = otsu_threshold(np_img=output_image)\n",
    "    output_image_hyst  = hysteresis_threshold(np_img=output_image, low=0.2, high=0.8)\n",
    "    output_image_basic = basic_threshold(np_img=output_image, threshold=0.2)\n",
    "    \n",
    "    ax[2].imshow(output_image_otsu, cmap='gray')\n",
    "    ax[2].set_title('{} (output)'.format(fname[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
