{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Runs our trained U-Net based model on test dataset and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet_model import *\n",
    "from oral_mice_tissues_dataset import *\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import utils\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Checking for GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print()\n",
    "print('Runing on: {}'.format(device))\n",
    "\n",
    "\n",
    "# create the datasets\n",
    "batch_size = 1\n",
    "color_normalization = \"1-original\"\n",
    "dataset_dir = \"/home/dalifreire/notebooks/github/histological_oral_mice_tissues/roi\"\n",
    "dataloaders = create_dataloader(method=color_normalization, batch_size=batch_size, dataset_dir=dataset_dir)\n",
    "\n",
    "\n",
    "# directory to save results\n",
    "seg_method = \"1-unet_based\"\n",
    "results_dir = \"results/{}/{}\".format(color_normalization, seg_method)\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "    \n",
    "# load the trained model\n",
    "epoch = 500\n",
    "model = UNet(in_channels=3, out_channels=1, padding=True).to(device)\n",
    "model = load_checkpoint(file_path=\"{}__Dataset-{}__Epoch-{}__Size-448x256.pt\".format(model.name(), color_normalization, epoch))\n",
    "\n",
    "\n",
    "# iterate over test dataset images        \n",
    "t1 = datetime.now()\n",
    "print(t1)\n",
    "for batch_idx, (images, masks, fname, original_size) in enumerate(dataloaders['test']):\n",
    "    \n",
    "    t = datetime.now()\n",
    "    \n",
    "    X = Variable(images.to(device))\n",
    "    print('Batch {}: {}/{} images: {} masks: {} {}'.format(\n",
    "        (batch_idx+1), \n",
    "        (batch_idx+1) * len(images), \n",
    "        len(dataloaders['test'].dataset),\n",
    "        images.shape,\n",
    "        masks.shape,\n",
    "        datetime.now()))\n",
    "    \n",
    "    \n",
    "    y_hat = model(X).squeeze(0)\n",
    "    X_numpy = X.cpu().numpy()\n",
    "    y_hat_numpy = y_hat.detach().cpu().numpy()\n",
    "    \n",
    "    \n",
    "    input_image_filename  = '{}/{} - input.png'.format(results_dir, fname[0][0:-4])\n",
    "    mask_image_filename   = '{}/{} - mask.png'.format(results_dir, fname[0][0:-4])\n",
    "    output_image_filename = '{}/{} - output - 1.png'.format(results_dir, fname[0][0:-4])\n",
    "    output_image_filename_otsu  = '{}/{} - output - 2 - otsu.png'.format(results_dir, fname[0][0:-4])\n",
    "    output_image_filename_hyst  = '{}/{} - output - 3 - hysteresis.png'.format(results_dir, fname[0][0:-4])\n",
    "    output_image_filename_basic = '{}/{} - output - 4 - basic.png'.format(results_dir, fname[0][0:-4])\n",
    "    f, ax = plt.subplots(1, 3, figsize=(20, 20))\n",
    "    \n",
    "    \n",
    "    # save the input image\n",
    "    input_image = images[0]\n",
    "    utils.save_image(input_image, input_image_filename)\n",
    "    ax[0].imshow(input_image.permute(1, 2, 0))\n",
    "    ax[0].set_title('{} (input)'.format(fname[0]))\n",
    "    \n",
    "    # save the mask image\n",
    "    mask_image = masks[0]\n",
    "    utils.save_image(mask_image, mask_image_filename)\n",
    "    ax[1].imshow(mask_image, cmap='gray')\n",
    "    ax[1].set_title('{} (mask)'.format(fname[0]))\n",
    "    \n",
    "    # save the predicted output image\n",
    "    output_image = y_hat[0].squeeze(0).detach().cpu().numpy()\n",
    "    output_image_otsu  = otsu_threshold(np_img=output_image)\n",
    "    output_image_hyst  = hysteresis_threshold(np_img=output_image, low=0.2, high=0.8)\n",
    "    output_image_basic = basic_threshold(np_img=output_image, threshold=0.2)\n",
    "    \n",
    "    utils.save_image(y_hat[0], output_image_filename)\n",
    "    utils.save_image(TF.to_tensor(np_to_pil(output_image_otsu)), output_image_filename_otsu)\n",
    "    utils.save_image(TF.to_tensor(np_to_pil(output_image_hyst)), output_image_filename_hyst)\n",
    "    utils.save_image(TF.to_tensor(np_to_pil(output_image_basic)), output_image_filename_basic)\n",
    "    \n",
    "    ax[2].imshow(output_image_hyst, cmap='gray')\n",
    "    ax[2].set_title('{} (output)'.format(fname[0]))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import utils\n",
    "from torchvision import transforms\n",
    "from image_utils import *\n",
    "from experimental_evaluation import *\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import collections\n",
    "\n",
    "color_norm_methods = [\"1-original\", \"2-khan_et_al\", \"3-macenko_et_al\", \"4-tosta_et_al\", \"5-reinhard_et_al\", \"6-vahadane_et_al\"]\n",
    "seg_methods = [\"1-unet_based\", \"2-de_oliveira_et_al_(2013)\", \"3-phoulady_et_al_(2016)\", \"4-vahadane_and_sethi_(2013)\", \"5-wienert_et_al_(2012)\"]\n",
    "results_dir = \"/home/dalifreire/notebooks/github/dysplastic_oral_tissues_segmentation/results\"\n",
    "#results_dir = \"/home/dalifreire/Documents/Doutorado/github/dysplastic_oral_tissues_segmentation/results\"\n",
    "\n",
    "for r, d, f in sorted(os.walk(results_dir)):\n",
    "    for norm_method in sorted(color_norm_methods):\n",
    "        if (r.endswith(norm_method)):\n",
    "            \n",
    "            print(r)\n",
    "            for seg_method in sorted(seg_methods):\n",
    "                \n",
    "                print(\"\\t{}\".format(seg_method))\n",
    "                seg_method_dir = \"{}/{}\".format(r, seg_method)\n",
    "                \n",
    "                for r_seg, d_seg, f_sef in sorted(os.walk(seg_method_dir)):\n",
    "                    for file in sorted(f_sef):\n",
    "                        \n",
    "                        threshold_type = \"output - 2 - otsu.png\" if seg_method == \"1-unet_based\" else \"output.png\"\n",
    "                        if file.lower().endswith(threshold_type):\n",
    "                            \n",
    "                            input_filename = \"{}/{}/{}\".format(r, seg_method, file.replace(threshold_type, 'input.png'))\n",
    "                            mask_filename = \"{}/{}/{}\".format(r, seg_method, file.replace(threshold_type, 'mask.png'))\n",
    "                            output_filename = \"{}/{}/{}\".format(r, seg_method, file)\n",
    "\n",
    "                            input_image = load_pil_image(input_filename)\n",
    "                            mask_image = load_pil_image(mask_filename, gray=True)\n",
    "                            output_image = load_pil_image(output_filename, gray=True)\n",
    "\n",
    "                            \n",
    "                            merge_image_output_b = cut_image_by_mask(input_image, output_image, inverse=True)\n",
    "                            merge_image_mask_b = cut_image_by_mask(input_image, mask_image, inverse=True)\n",
    "\n",
    "                            merge_image_output_f = cut_image_by_mask(input_image, output_image, inverse=False)\n",
    "                            merge_image_mask_f = cut_image_by_mask(input_image, mask_image, inverse=False)\n",
    "\n",
    "                                                        \n",
    "                            utils.save_image(transforms.ToTensor()(merge_image_output_f), output_filename.replace(\".png\", \"_2.png\"))\n",
    "                            utils.save_image(transforms.ToTensor()(merge_image_mask_f), output_filename.replace(\".png\", \"_3.png\"))\n",
    "                            \n",
    "                            utils.save_image(transforms.ToTensor()(merge_image_output_b), output_filename.replace(\".png\", \"_4.png\"))\n",
    "                            utils.save_image(transforms.ToTensor()(merge_image_mask_b), output_filename.replace(\".png\", \"_5.png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import utils\n",
    "from image_utils import *\n",
    "from experimental_evaluation import *\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import collections\n",
    "\n",
    "\n",
    "color_norm_methods = [\"1-original\"]\n",
    "seg_methods = [\"1-unet_based\"]\n",
    "results_dir = \"/home/dalifreire/notebooks/github/dysplastic_oral_tissues_segmentation/results\"\n",
    "#results_dir = \"/home/dalifreire/Documents/Doutorado/github/dysplastic_oral_tissues_segmentation/results\"\n",
    "\n",
    "for r, d, f in sorted(os.walk(results_dir)):\n",
    "    for norm_method in sorted(color_norm_methods):\n",
    "        if (r.endswith(norm_method)):\n",
    "            \n",
    "            print(r)\n",
    "            for seg_method in sorted(seg_methods):\n",
    "                \n",
    "                print(\"\\t{}\".format(seg_method))\n",
    "                seg_method_dir = \"{}/{}\".format(r, seg_method)\n",
    "                \n",
    "                with open('{}/quantitative_analysis_otsu.csv'.format(seg_method_dir), mode='w') as medidas_file:\n",
    "                    medidas_writer = csv.writer(medidas_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    medidas_writer.writerow(['image', 'accuracy', 'precision', 'f1/dice', 'jaccard', 'sensitivity/recall', 'specificity'])\n",
    "                \n",
    "                    for r_seg, d_seg, f_sef in sorted(os.walk(seg_method_dir)):\n",
    "                        for file in sorted(f_sef):\n",
    "                            \n",
    "                            threshold_type = \"output - 2 - otsu.png\" if seg_method == \"1-unet_based\" else \"output.png\"\n",
    "                            if file.lower().endswith(threshold_type):\n",
    "\n",
    "                                mask_filename = \"{}/{}/{}\".format(r, seg_method, file.replace(threshold_type, \"mask.png\"))\n",
    "                                output_filename = \"{}/{}/{}\".format(r, seg_method, file)\n",
    "                                \n",
    "                                accuracy = pixel_accuracy_score(mask_filename, output_filename)\n",
    "                                jaccard = jaccard_index_score(mask_filename, output_filename)\n",
    "                                precision = precision_score(mask_filename, output_filename)\n",
    "                                recall = recall_score(mask_filename, output_filename)\n",
    "                                f1 = f1_score(mask_filename, output_filename)\n",
    "                                sensitivity = sensitivity_score(mask_filename, output_filename)\n",
    "                                specificity = specificity_score(mask_filename, output_filename)\n",
    "                                dice = dice_score(mask_filename, output_filename)\n",
    "                                \n",
    "                                print(file.replace(\" - \" + threshold_type, \"\"))\n",
    "                                print('\\t{}: \\t\\t{}'.format('accuracy', accuracy))\n",
    "                                print('\\t{}: \\t\\t{}'.format('precision', precision))\n",
    "                                print('\\t{}: \\t\\t{}'.format('f1/dice', f1))\n",
    "                                print('\\t{}: \\t\\t{}'.format('jaccard', jaccard))\n",
    "                                print('\\t{}: \\t{}'.format('sensitivity/recall', sensitivity))\n",
    "                                print('\\t{}: \\t\\t{}'.format('specificity', specificity))\n",
    "                                print()\n",
    "\n",
    "                                medidas_writer.writerow([file.replace(\" - \" + threshold_type, \"\"), accuracy, precision, f1, jaccard, sensitivity, specificity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
